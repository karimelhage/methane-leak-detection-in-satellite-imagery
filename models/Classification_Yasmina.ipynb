{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fce0ee4a",
      "metadata": {
        "id": "fce0ee4a"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch \n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "vxy5xJDTuq74",
      "metadata": {
        "id": "vxy5xJDTuq74"
      },
      "source": [
        "## Creation of Train and Validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "orXv3QYXWM31",
      "metadata": {
        "id": "orXv3QYXWM31"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('metadata.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "-4riHs_cW3gA",
      "metadata": {
        "id": "-4riHs_cW3gA"
      },
      "outputs": [],
      "source": [
        "paths = df.groupby([\"lat\",\"lon\",\"plume\"]).count()[['path']].sort_values(\"path\", ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "i63J7U9kXQZ9",
      "metadata": {
        "id": "i63J7U9kXQZ9"
      },
      "outputs": [],
      "source": [
        "paths['lists'] = np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "nTGcOGW3Xl5R",
      "metadata": {
        "id": "nTGcOGW3Xl5R"
      },
      "outputs": [],
      "source": [
        "temp = []\n",
        "\n",
        "for i,row in enumerate(paths.iterrows()):\n",
        "  row = row[0]\n",
        "  temp.append(list(df['path'][(df['lat'] == row[0]) & (df['lon'] == row[1])]))\n",
        "\n",
        "paths['lists'] = temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "W0eHLAI6dGha",
      "metadata": {
        "id": "W0eHLAI6dGha"
      },
      "outputs": [],
      "source": [
        "paths = paths.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "UgJsSAhie35F",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "UgJsSAhie35F",
        "outputId": "7486f476-42e5-4228-af0b-1f9bc720115a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "      <th>plume</th>\n",
              "      <th>path</th>\n",
              "      <th>lists</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>29.631951</td>\n",
              "      <td>35.952379</td>\n",
              "      <td>no</td>\n",
              "      <td>21</td>\n",
              "      <td>[images/no_plume/20230304_methane_mixing_ratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>32.713854</td>\n",
              "      <td>44.609398</td>\n",
              "      <td>no</td>\n",
              "      <td>19</td>\n",
              "      <td>[images/no_plume/20230219_methane_mixing_ratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33.990812</td>\n",
              "      <td>39.641866</td>\n",
              "      <td>no</td>\n",
              "      <td>18</td>\n",
              "      <td>[images/no_plume/20230206_methane_mixing_ratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>28.510000</td>\n",
              "      <td>77.442400</td>\n",
              "      <td>yes</td>\n",
              "      <td>17</td>\n",
              "      <td>[images/plume/20230327_methane_mixing_ratio_id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36.596520</td>\n",
              "      <td>38.321405</td>\n",
              "      <td>no</td>\n",
              "      <td>15</td>\n",
              "      <td>[images/no_plume/20230122_methane_mixing_ratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>21.039986</td>\n",
              "      <td>-77.824694</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>[images/no_plume/20230227_methane_mixing_ratio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>24.907500</td>\n",
              "      <td>67.023000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "      <td>[images/plume/20230404_methane_mixing_ratio_id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>23.763333</td>\n",
              "      <td>86.396667</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "      <td>[images/plume/20230129_methane_mixing_ratio_id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>23.740000</td>\n",
              "      <td>90.595000</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "      <td>[images/plume/20230206_methane_mixing_ratio_id...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>68.570113</td>\n",
              "      <td>25.563059</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>[images/no_plume/20230404_methane_mixing_ratio...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>101 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           lat        lon plume  path   \n",
              "0    29.631951  35.952379    no    21  \\\n",
              "1    32.713854  44.609398    no    19   \n",
              "2    33.990812  39.641866    no    18   \n",
              "3    28.510000  77.442400   yes    17   \n",
              "4    36.596520  38.321405    no    15   \n",
              "..         ...        ...   ...   ...   \n",
              "96   21.039986 -77.824694    no     1   \n",
              "97   24.907500  67.023000   yes     1   \n",
              "98   23.763333  86.396667   yes     1   \n",
              "99   23.740000  90.595000   yes     1   \n",
              "100  68.570113  25.563059    no     1   \n",
              "\n",
              "                                                 lists  \n",
              "0    [images/no_plume/20230304_methane_mixing_ratio...  \n",
              "1    [images/no_plume/20230219_methane_mixing_ratio...  \n",
              "2    [images/no_plume/20230206_methane_mixing_ratio...  \n",
              "3    [images/plume/20230327_methane_mixing_ratio_id...  \n",
              "4    [images/no_plume/20230122_methane_mixing_ratio...  \n",
              "..                                                 ...  \n",
              "96   [images/no_plume/20230227_methane_mixing_ratio...  \n",
              "97   [images/plume/20230404_methane_mixing_ratio_id...  \n",
              "98   [images/plume/20230129_methane_mixing_ratio_id...  \n",
              "99   [images/plume/20230206_methane_mixing_ratio_id...  \n",
              "100  [images/no_plume/20230404_methane_mixing_ratio...  \n",
              "\n",
              "[101 rows x 5 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paths"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "pa-V67aYumtd",
      "metadata": {
        "id": "pa-V67aYumtd"
      },
      "source": [
        "### Split By Location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "RjAuwf0fckMx",
      "metadata": {
        "id": "RjAuwf0fckMx"
      },
      "outputs": [],
      "source": [
        "val_indexs = list(paths[paths['plume'] == 'yes'].sample(int(len(paths)*0.1)).index) +\\\n",
        "list(paths[paths['plume'] == 'no'].sample(int(len(paths)*0.1)).index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "hIxGDSY5UtRI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIxGDSY5UtRI",
        "outputId": "011de348-ca7b-4d13-bc4a-bc8c77fb3122"
      },
      "outputs": [],
      "source": [
        "# creating validition set\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# set up paths\n",
        "data_dir = 'images'\n",
        "val_dir = 'validation'\n",
        "train_dir='train'\n",
        "\n",
        "plume_dir = 'plume'\n",
        "no_plume_dir = 'no_plume'\n",
        "\n",
        "\n",
        "\n",
        "# create validation directories\n",
        "os.makedirs(os.path.join(train_dir, plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, no_plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, no_plume_dir), exist_ok=True)\n",
        "\n",
        "# get filenames from true and false directories\n",
        "val_plume_files = set([y.strip(\"images/plume/\")+str('.tif') for x in list(paths.lists[paths.index.isin(val_indexs[:10])]) for y in x])\n",
        "val_no_plume_files = set([y.strip(\"images/no_plume/\")+str('.tif') for x in list(paths.lists[paths.index.isin(val_indexs[10:])]) for y in x])\n",
        "train_files = paths[~paths.index.isin(val_indexs)]\n",
        "train_plume_files = set([y.strip(\"images/plume/\")+str('.tif') for x in list(train_files.lists[train_files.plume == \"yes\"]) for y in x])\n",
        "train_no_plume_files = set([y.strip(\"images/no_plume/\")+str('.tif') for x in list(train_files.lists[train_files.plume == \"no\"]) for y in x])\n",
        "\n",
        "# # move sampled files to validation directories\n",
        "for filename in val_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, plume_dir, filename),\n",
        "                os.path.join( val_dir, plume_dir))\n",
        "for filename in val_no_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, no_plume_dir, filename),\n",
        "                os.path.join(val_dir, no_plume_dir))\n",
        "for filename in train_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, plume_dir, filename),\n",
        "                os.path.join( train_dir, plume_dir))\n",
        "for filename in train_no_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, no_plume_dir, filename),\n",
        "                os.path.join(train_dir, no_plume_dir))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "DmAQtWpVuur9",
      "metadata": {
        "id": "DmAQtWpVuur9"
      },
      "source": [
        "### Split By Having each location in training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "pXJer1u0voP9",
      "metadata": {
        "collapsed": true,
        "id": "pXJer1u0voP9"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "val_index = [] \n",
        "\n",
        "for x in list(paths.lists):\n",
        "  val_index.extend(set(list(random.sample(x, int(len(x)*0.35)))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "CQREJhkVyYYu",
      "metadata": {
        "id": "CQREJhkVyYYu"
      },
      "outputs": [],
      "source": [
        "L = set([y for x in paths.lists for y in x])\n",
        "\n",
        "for item in val_index:\n",
        "    if item in L:\n",
        "        L.remove(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "_Q1DzQRQy4ip",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q1DzQRQy4ip",
        "outputId": "cd569bb7-c70b-4365-d7c1-d0b3b404b2a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "319"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "3eryBP5Ry8e7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eryBP5Ry8e7",
        "outputId": "0646e1ae-df1e-46ae-e076-61c07b4f97b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "428"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(set([y for x in paths.lists for y in x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "mEG10VG9wWuP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEG10VG9wWuP",
        "outputId": "df016695-dc60-4bc3-dad0-270a1546eabb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "109"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "gDKD82CLuur_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDKD82CLuur_",
        "outputId": "8fb9d1ef-360f-4eb7-cae5-18bac6ac9612"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 3] The system cannot find the path specified: \"'/content/drive/Shareddrives/QB Hacakthon'\"\n",
            "c:\\Users\\CompuTop\\Desktop\\Hackathon QB\\methane-leak-detection-in-satellite-imagery\\models\n",
            "48\n",
            "61\n",
            "166\n",
            "153\n"
          ]
        }
      ],
      "source": [
        "# creating validition set\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "%cd '/content/drive/Shareddrives/QB Hacakthon'\n",
        "\n",
        "# set up paths\n",
        "data_dir = 'images'\n",
        "val_dir = 'validation_each_location'\n",
        "train_dir='train_each_location'\n",
        "\n",
        "plume_dir = 'plume'\n",
        "no_plume_dir = 'no_plume'\n",
        "\n",
        "val_plume_files = []\n",
        "val_no_plume_files = []\n",
        "train_plume_files = []\n",
        "train_no_plume_files = []\n",
        "\n",
        "# create validation directories\n",
        "os.makedirs(os.path.join(train_dir, plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_dir, no_plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, plume_dir), exist_ok=True)\n",
        "os.makedirs(os.path.join(val_dir, no_plume_dir), exist_ok=True)\n",
        "\n",
        "# get filenames from true and false directories\n",
        "for val in val_index:\n",
        "  if 'no_plume' in val:\n",
        "    val_no_plume_files.append(val)\n",
        "  else:\n",
        "    val_plume_files.append(val)\n",
        "\n",
        "for val in L:\n",
        "  if 'no_plume' in val:\n",
        "    train_no_plume_files.append(val)\n",
        "  else:\n",
        "    train_plume_files.append(val)\n",
        "\n",
        "val_plume_files = set([y.strip(\"images/plume/\")+str('.tif') for y in val_plume_files])\n",
        "val_no_plume_files = set([y.strip(\"images/no_plume/\")+str('.tif') for y in val_no_plume_files])\n",
        "train_plume_files = set([y.strip(\"images/plume/\")+str('.tif') for y in train_plume_files])\n",
        "train_no_plume_files = set([y.strip(\"images/no_plume/\")+str('.tif') for y in train_no_plume_files])\n",
        "\n",
        "print(len(val_plume_files))\n",
        "print(len(val_no_plume_files))\n",
        "print(len(train_plume_files))\n",
        "print(len(train_no_plume_files))\n",
        "\n",
        "# # move sampled files to validation directories\n",
        "for filename in val_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, plume_dir, filename),\n",
        "                os.path.join( val_dir, plume_dir))\n",
        "for filename in val_no_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, no_plume_dir, filename),\n",
        "                os.path.join(val_dir, no_plume_dir))\n",
        "for filename in train_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, plume_dir, filename),\n",
        "                os.path.join( train_dir, plume_dir))\n",
        "for filename in train_no_plume_files:\n",
        "    shutil.move(os.path.join(data_dir, no_plume_dir, filename),\n",
        "                os.path.join(train_dir, no_plume_dir))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c98a0375",
      "metadata": {
        "id": "c98a0375"
      },
      "source": [
        "## Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "b79c8d22",
      "metadata": {
        "id": "b79c8d22"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, augment=False):\n",
        "        self.root_dir = root_dir\n",
        "        self.augment = augment\n",
        "        self.image_list = []\n",
        "        self.labels = []\n",
        "        self.augmented_images = []\n",
        "\n",
        "        classes = os.listdir(root_dir)\n",
        "        for class_name in classes:\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                image_names = os.listdir(class_dir)\n",
        "                tiff_image_names = [img_name for img_name in image_names if img_name.lower().endswith('.tiff') or img_name.lower().endswith('.tif')]\n",
        "                self.image_list.extend([os.path.join(class_dir, img_name) for img_name in tiff_image_names])\n",
        "                self.labels.extend([1 if class_name == 'plume' else 0] * len(tiff_image_names))\n",
        "\n",
        "                if augment:\n",
        "                    augmented_images = []\n",
        "                    for img_name in image_names:\n",
        "                        img_path = os.path.join(class_dir, img_name)\n",
        "                        image = Image.open(img_path)\n",
        "                        image = image.resize((64, 64))  # Resize to 64x64\n",
        "\n",
        "                        # Apply augmentation transformations\n",
        "                        transform = transforms.Compose([\n",
        "                            transforms.RandomHorizontalFlip(),\n",
        "                            transforms.RandomRotation(10),\n",
        "                            transforms.ToTensor()\n",
        "                        ])\n",
        "                        augmented_image = transform(image)\n",
        "                        augmented_images.append(augmented_image)\n",
        "\n",
        "                    self.augmented_images.extend(augmented_images)\n",
        "\n",
        "        if augment:\n",
        "            self.image_list += self.augmented_images\n",
        "            self.labels += self.labels * len(self.augmented_images)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.image_list[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if isinstance(image, str):\n",
        "            image = Image.open(image)\n",
        "            image = image.resize((64, 64))  # Resize to 64x64\n",
        "\n",
        "            transform = transforms.Compose([\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "            image = transform(image)\n",
        "\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d30ff78e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d30ff78e",
        "outputId": "ac737357-5ed4-48cb-f7fa-a09405df850a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train batch - Images: torch.Size([32, 1, 64, 64]), Labels: torch.Size([32])\n",
            "Validation batch - Images: torch.Size([32, 1, 64, 64]), Labels: torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "gen = torch.Generator()\n",
        "gen.manual_seed(0)\n",
        "\n",
        "root_dir = \"/content/drive/Shareddrives/QB Hacakthon/train_each_location\"\n",
        "val_dir = \"/content/drive/Shareddrives/QB Hacakthon/validation_each_location\"\n",
        "\n",
        "train_dataset = CustomDataset(root_dir, augment=True)\n",
        "val_dataset = CustomDataset(val_dir, augment=False)\n",
        "\n",
        "\n",
        "# Define batch size for training and validation\n",
        "batch_size = 32\n",
        "\n",
        "# Create the train DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Create the validation DataLoader\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Verify the train and validation data loaders\n",
        "for images, labels in train_loader:\n",
        "    print(f\"Train batch - Images: {images.shape}, Labels: {labels.shape}\")\n",
        "    break\n",
        "\n",
        "for images, labels in val_loader:\n",
        "    print(f\"Validation batch - Images: {images.shape}, Labels: {labels.shape}\")\n",
        "    break"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "0baf66a2",
      "metadata": {
        "id": "0baf66a2"
      },
      "source": [
        "## Resnet101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a8e9a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5a8e9a3",
        "outputId": "de7c6b81-1e96-4bb1-f1ff-985c086a4d1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 171M/171M [00:02<00:00, 80.1MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define the device for training (CPU or GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained ResNet101 model\n",
        "resnet = models.resnet101(weights='ResNet101_Weights.IMAGENET1K_V1')\n",
        "\n",
        "# Modify the first layer to accept single-channel grayscale images\n",
        "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last fully connected layer for binary classification with softmax activation\n",
        "num_classes = 2  # 2 classes: 1 or 0\n",
        "resnet.fc = nn.Sequential(\n",
        "    nn.Linear(resnet.fc.in_features, num_classes)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427359ad",
      "metadata": {
        "id": "427359ad"
      },
      "outputs": [],
      "source": [
        "# Move the model to the device\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "# Define the loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.Adam(resnet.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b91da0b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b91da0b",
        "outputId": "f02de279-63cc-4568-b79c-8ad68fdfc585",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   5%|â–Œ         | 1/20 [00:32<10:14, 32.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.2702702702702703\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  10%|â–ˆ         | 2/20 [00:35<04:28, 14.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5225225225225225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  15%|â–ˆâ–Œ        | 3/20 [00:38<02:44,  9.67s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6126126126126126\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|â–ˆâ–ˆ        | 4/20 [00:41<01:51,  6.98s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6756756756756757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:44<01:21,  5.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7657657657657657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:46<01:03,  4.50s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.43243243243243246\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:49<00:50,  3.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6216216216216216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:52<00:42,  3.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.46846846846846846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:55<00:36,  3.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5855855855855856\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:57<00:31,  3.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5315315315315315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:00<00:27,  3.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.38738738738738737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:03<00:23,  2.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7027027027027027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:05<00:20,  2.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.4774774774774775\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:08<00:17,  2.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5765765765765766\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:11<00:14,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6846846846846847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [01:14<00:11,  2.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6846846846846847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [01:16<00:08,  2.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6486486486486487\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [01:19<00:05,  2.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6306306306306306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [01:22<00:02,  2.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.4864864864864865\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:25<00:00,  4.27s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6756756756756757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    resnet.train()  # Set the model to training mode\n",
        "    \n",
        "    epoch_loss = 0.0  # Accumulator for epoch loss\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = resnet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Accumulate the loss\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    # Compute the average loss for the epoch\n",
        "    epoch_loss /= len(train_loader)\n",
        "#     tqdm.write(f\"Epoch {epoch+1}/{num_epochs} - Average Loss: {epoch_loss}\")\n",
        "\n",
        "    # Validation loop\n",
        "    resnet.eval()  # Set the model to evaluation mode\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = resnet(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Validation Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ecc049",
      "metadata": {
        "id": "d7ecc049"
      },
      "outputs": [],
      "source": [
        "model_path = 'resnet_model.pth'\n",
        "\n",
        "# Save the model\n",
        "torch.save(resnet.state_dict(), model_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "Lr9dT8gns4mN",
      "metadata": {
        "id": "Lr9dT8gns4mN"
      },
      "source": [
        "## Wide_ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "qR_cS1LmtVx8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qR_cS1LmtVx8",
        "outputId": "dc39140b-6e6c-4a87-c3f9-c3a9c96860bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/wide_resnet50_2-95faca4d.pth\" to /root/.cache/torch/hub/checkpoints/wide_resnet50_2-95faca4d.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 132M/132M [00:01<00:00, 81.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define the device for training (CPU or GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained ResNet101 model\n",
        "resnet = models.wide_resnet50_2(weights='Wide_ResNet50_2_Weights.IMAGENET1K_V1')\n",
        "\n",
        "# Modify the first layer to accept single-channel grayscale images\n",
        "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last fully connected layer for binary classification with softmax activation\n",
        "num_classes = 2  # 2 classes: 1 or 0\n",
        "resnet.fc = nn.Sequential(\n",
        "    nn.Linear(resnet.fc.in_features, num_classes)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ZHRyJw7OtWW4",
      "metadata": {
        "id": "ZHRyJw7OtWW4"
      },
      "outputs": [],
      "source": [
        "max_lr = 1e-2\n",
        "num_epochs = 20\n",
        "\n",
        "# Move the model to the device\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "# Define the loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.AdamW(resnet.parameters(), lr=max_lr)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=num_epochs,\n",
        "                                               steps_per_epoch=len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "glqRa_AVPkHT",
      "metadata": {
        "id": "glqRa_AVPkHT"
      },
      "outputs": [],
      "source": [
        "# Retrieve the current learning rate of the optimizer\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "LmAOvFOQs3WZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmAOvFOQs3WZ",
        "outputId": "99d54e63-b9f5-4ded-981a-e7220423f647"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   5%|â–Œ         | 1/20 [00:38<12:16, 38.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7889908256880734\n",
            "Validation F1 Score: 0.7800298324120383\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.89      0.82        61\n",
            "           1       0.82      0.67      0.74        48\n",
            "\n",
            "    accuracy                           0.79       109\n",
            "   macro avg       0.80      0.78      0.78       109\n",
            "weighted avg       0.79      0.79      0.79       109\n",
            "\n",
            "Validation AUC: 0.8333333333333334\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  10%|â–ˆ         | 2/20 [00:41<05:20, 17.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6146788990825688\n",
            "Validation F1 Score: 0.6143867924528301\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.57      0.62        61\n",
            "           1       0.55      0.67      0.60        48\n",
            "\n",
            "    accuracy                           0.61       109\n",
            "   macro avg       0.62      0.62      0.61       109\n",
            "weighted avg       0.63      0.61      0.62       109\n",
            "\n",
            "Validation AUC: 0.6256830601092895\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  15%|â–ˆâ–Œ        | 3/20 [00:44<03:07, 11.01s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7706422018348624\n",
            "Validation F1 Score: 0.7642121657869689\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.84      0.80        61\n",
            "           1       0.77      0.69      0.73        48\n",
            "\n",
            "    accuracy                           0.77       109\n",
            "   macro avg       0.77      0.76      0.76       109\n",
            "weighted avg       0.77      0.77      0.77       109\n",
            "\n",
            "Validation AUC: 0.826844262295082\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|â–ˆâ–ˆ        | 4/20 [00:47<02:05,  7.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7247706422018348\n",
            "Validation F1 Score: 0.7228813559322034\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.72      0.75        61\n",
            "           1       0.67      0.73      0.70        48\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.72      0.73      0.72       109\n",
            "weighted avg       0.73      0.72      0.73       109\n",
            "\n",
            "Validation AUC: 0.7745901639344261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\rEpochs:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:50<01:30,  6.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.44036697247706424\n",
            "Validation F1 Score: 0.3057324840764331\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        61\n",
            "           1       0.44      1.00      0.61        48\n",
            "\n",
            "    accuracy                           0.44       109\n",
            "   macro avg       0.22      0.50      0.31       109\n",
            "weighted avg       0.19      0.44      0.27       109\n",
            "\n",
            "Validation AUC: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "\rEpochs:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:54<01:15,  5.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.44036697247706424\n",
            "Validation F1 Score: 0.3057324840764331\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        61\n",
            "           1       0.44      1.00      0.61        48\n",
            "\n",
            "    accuracy                           0.44       109\n",
            "   macro avg       0.22      0.50      0.31       109\n",
            "weighted avg       0.19      0.44      0.27       109\n",
            "\n",
            "Validation AUC: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:58<01:01,  4.75s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.4954128440366973\n",
            "Validation F1 Score: 0.441025641025641\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.16      0.27        61\n",
            "           1       0.46      0.92      0.62        48\n",
            "\n",
            "    accuracy                           0.50       109\n",
            "   macro avg       0.59      0.54      0.44       109\n",
            "weighted avg       0.60      0.50      0.42       109\n",
            "\n",
            "Validation AUC: 0.3782445355191257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [01:01<00:50,  4.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6330275229357798\n",
            "Validation F1 Score: 0.6126510305614783\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.36      0.52        61\n",
            "           1       0.55      0.98      0.70        48\n",
            "\n",
            "    accuracy                           0.63       109\n",
            "   macro avg       0.75      0.67      0.61       109\n",
            "weighted avg       0.78      0.63      0.60       109\n",
            "\n",
            "Validation AUC: 0.8043032786885245\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:04<00:41,  3.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7247706422018348\n",
            "Validation F1 Score: 0.7241902834008096\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.61      0.71        61\n",
            "           1       0.64      0.88      0.74        48\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.75      0.74      0.72       109\n",
            "weighted avg       0.76      0.72      0.72       109\n",
            "\n",
            "Validation AUC: 0.7592213114754099\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:07<00:35,  3.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5688073394495413\n",
            "Validation F1 Score: 0.5334668973681814\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.26      0.41        61\n",
            "           1       0.51      0.96      0.66        48\n",
            "\n",
            "    accuracy                           0.57       109\n",
            "   macro avg       0.70      0.61      0.53       109\n",
            "weighted avg       0.72      0.57      0.52       109\n",
            "\n",
            "Validation AUC: 0.7571721311475409\n",
            "Validation Accuracy: 0.8165137614678899\n",
            "Validation F1 Score: 0.8138661202185793\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84        61\n",
            "           1       0.79      0.79      0.79        48\n",
            "\n",
            "    accuracy                           0.82       109\n",
            "   macro avg       0.81      0.81      0.81       109\n",
            "weighted avg       0.82      0.82      0.82       109\n",
            "\n",
            "Validation AUC: 0.85724043715847\n",
            "-----------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:13<00:26,  3.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5779816513761468\n",
            "Validation F1 Score: 0.5458333333333333\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.28      0.42        61\n",
            "           1       0.51      0.96      0.67        48\n",
            "\n",
            "    accuracy                           0.58       109\n",
            "   macro avg       0.70      0.62      0.55       109\n",
            "weighted avg       0.73      0.58      0.53       109\n",
            "\n",
            "Validation AUC: 0.8886612021857924\n",
            "Validation Accuracy: 0.8256880733944955\n",
            "Validation F1 Score: 0.8208012459980965\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.89      0.85        61\n",
            "           1       0.84      0.75      0.79        48\n",
            "\n",
            "    accuracy                           0.83       109\n",
            "   macro avg       0.83      0.82      0.82       109\n",
            "weighted avg       0.83      0.83      0.82       109\n",
            "\n",
            "Validation AUC: 0.8838797814207651\n",
            "-----------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:16<00:23,  3.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8348623853211009\n",
            "Validation F1 Score: 0.8316746739876459\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.87      0.85        61\n",
            "           1       0.83      0.79      0.81        48\n",
            "\n",
            "    accuracy                           0.83       109\n",
            "   macro avg       0.83      0.83      0.83       109\n",
            "weighted avg       0.83      0.83      0.83       109\n",
            "\n",
            "Validation AUC: 0.878756830601093\n",
            "-----------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:24<00:17,  3.57s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7981651376146789\n",
            "Validation F1 Score: 0.7960884353741496\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.80      0.82        61\n",
            "           1       0.76      0.79      0.78        48\n",
            "\n",
            "    accuracy                           0.80       109\n",
            "   macro avg       0.80      0.80      0.80       109\n",
            "weighted avg       0.80      0.80      0.80       109\n",
            "\n",
            "Validation AUC: 0.8777322404371585\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [01:27<00:13,  3.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7431192660550459\n",
            "Validation F1 Score: 0.7430976430976431\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.67      0.75        61\n",
            "           1       0.67      0.83      0.74        48\n",
            "\n",
            "    accuracy                           0.74       109\n",
            "   macro avg       0.75      0.75      0.74       109\n",
            "weighted avg       0.76      0.74      0.74       109\n",
            "\n",
            "Validation AUC: 0.8633879781420765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [01:30<00:09,  3.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7339449541284404\n",
            "Validation F1 Score: 0.7339449541284403\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.66      0.73        61\n",
            "           1       0.66      0.83      0.73        48\n",
            "\n",
            "    accuracy                           0.73       109\n",
            "   macro avg       0.74      0.74      0.73       109\n",
            "weighted avg       0.76      0.73      0.73       109\n",
            "\n",
            "Validation AUC: 0.8551912568306012\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [01:33<00:06,  3.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7247706422018348\n",
            "Validation F1 Score: 0.7247474747474747\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72        61\n",
            "           1       0.65      0.83      0.73        48\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.74      0.74      0.72       109\n",
            "weighted avg       0.75      0.72      0.72       109\n",
            "\n",
            "Validation AUC: 0.8623633879781422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [01:36<00:03,  3.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7247706422018348\n",
            "Validation F1 Score: 0.7247474747474747\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.64      0.72        61\n",
            "           1       0.65      0.83      0.73        48\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.74      0.74      0.72       109\n",
            "weighted avg       0.75      0.72      0.72       109\n",
            "\n",
            "Validation AUC: 0.8582650273224043\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:39<00:00,  4.99s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7339449541284404\n",
            "Validation F1 Score: 0.7339449541284403\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.66      0.73        61\n",
            "           1       0.66      0.83      0.73        48\n",
            "\n",
            "    accuracy                           0.73       109\n",
            "   macro avg       0.74      0.74      0.73       109\n",
            "weighted avg       0.76      0.73      0.73       109\n",
            "\n",
            "Validation AUC: 0.8534836065573771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "best_accuracy = 0.0\n",
        "lrs = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    resnet.train()  # Set the model to training mode\n",
        "    \n",
        "    epoch_loss = 0.0  # Accumulator for epoch loss\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = resnet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Step the learning rate\n",
        "        lrs.append(get_lr(optimizer))\n",
        "        scheduler.step() \n",
        "        \n",
        "        # Accumulate the loss\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    # Compute the average loss for the epoch\n",
        "    epoch_loss /= len(train_loader)\n",
        "\n",
        "    # Validation loop\n",
        "    resnet.eval()  # Set the model to evaluation mode\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "    true_probabilities = []\n",
        "    predicted_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = resnet(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Collect predicted and true labels for classification report\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Collect predicted probabilities and true labels\n",
        "            predicted_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Assuming binary classification\n",
        "            true_probabilities.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "    # Compute F1 score and classification report\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "    classification_rep = classification_report(true_labels, predicted_labels)\n",
        "    print(f\"Validation F1 Score: {f1}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_rep)\n",
        "\n",
        "    # Compute the AUC\n",
        "    auc = roc_auc_score(true_probabilities, predicted_probabilities)\n",
        "    print(f\"Validation AUC: {auc}\")\n",
        "    \n",
        "    if accuracy > 0.8 and accuracy > best_accuracy:\n",
        "      print('-----------------------------------------------------------')\n",
        "      model_path = 'Wide_ResNet50_Weights'+str(epoch)+'.pth'\n",
        "      best_accuracy = accuracy\n",
        "\n",
        "      # Save the model\n",
        "      torch.save(resnet.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8RIrTv2I6GDs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RIrTv2I6GDs",
        "outputId": "5b95ecfa-9764-420b-b4e6-ef00c1977b0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): Linear(in_features=2048, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "gcPaFfQj7Vr-",
      "metadata": {
        "id": "gcPaFfQj7Vr-"
      },
      "outputs": [],
      "source": [
        "resnet.load_state_dict(torch.load('/content/New_split_each_location_Wide_ResNet50.pth'))\n",
        "\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "torch.save(resnet.state_dict(), '/content/drive/Shareddrives/QB Hacakthon/models path/Wide_ResNet50_2_Weights10.pth')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "MKUqNt5O-BsW",
      "metadata": {
        "id": "MKUqNt5O-BsW"
      },
      "source": [
        "## ResNeXt101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "nDWZaaYW-Bsq",
      "metadata": {
        "id": "nDWZaaYW-Bsq"
      },
      "outputs": [],
      "source": [
        "# Define the device for training (CPU or GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained ResNet101 model\n",
        "#resnet = models.resnext101_64x4d(weights='ResNeXt101_64X4D_Weights.IMAGENET1K_V1')\n",
        "resnet = models.resnet101(weights='ResNet101_Weights.IMAGENET1K_V1')\n",
        "\n",
        "# Modify the first layer to accept single-channel grayscale images\n",
        "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "# Modify the last fully connected layer for binary classification with softmax activation\n",
        "num_classes = 2  # 2 classes: 1 or 0\n",
        "resnet.fc = nn.Sequential(\n",
        "    nn.Linear(resnet.fc.in_features, num_classes)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "AVPOoajK-Bsr",
      "metadata": {
        "id": "AVPOoajK-Bsr"
      },
      "outputs": [],
      "source": [
        "max_lr = 1e-2\n",
        "num_epochs = 20\n",
        "weight_decay = 1e-4\n",
        "\n",
        "# Move the model to the device\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "# Define the loss function (criterion)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.AdamW(resnet.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=num_epochs,\n",
        "                                               steps_per_epoch=len(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "WR8XaYuM_7cG",
      "metadata": {
        "id": "WR8XaYuM_7cG"
      },
      "outputs": [],
      "source": [
        "# Retrieve the current learning rate of the optimizer\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "DE1MJKfT-Bss",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE1MJKfT-Bss",
        "outputId": "662a45b2-64dc-482a-e965-f1ba0a0c8c2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:   5%|â–Œ         | 1/20 [00:03<00:58,  3.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.44954128440366975\n",
            "Validation F1 Score: 0.32382133995037216\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.02      0.03        61\n",
            "           1       0.44      1.00      0.62        48\n",
            "\n",
            "    accuracy                           0.45       109\n",
            "   macro avg       0.72      0.51      0.32       109\n",
            "weighted avg       0.76      0.45      0.29       109\n",
            "\n",
            "Validation AUC: 0.5715505464480874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  10%|â–ˆ         | 2/20 [00:05<00:52,  2.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.46788990825688076\n",
            "Validation F1 Score: 0.3801960784313725\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.08      0.15        61\n",
            "           1       0.45      0.96      0.61        48\n",
            "\n",
            "    accuracy                           0.47       109\n",
            "   macro avg       0.58      0.52      0.38       109\n",
            "weighted avg       0.60      0.47      0.35       109\n",
            "\n",
            "Validation AUC: 0.7392418032786885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  15%|â–ˆâ–Œ        | 3/20 [00:08<00:48,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5779816513761468\n",
            "Validation F1 Score: 0.5750847457627117\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.44      0.54        61\n",
            "           1       0.51      0.75      0.61        48\n",
            "\n",
            "    accuracy                           0.58       109\n",
            "   macro avg       0.60      0.60      0.58       109\n",
            "weighted avg       0.61      0.58      0.57       109\n",
            "\n",
            "Validation AUC: 0.6618852459016394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  20%|â–ˆâ–ˆ        | 4/20 [00:11<00:45,  2.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.5137614678899083\n",
            "Validation F1 Score: 0.47940884923853294\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.23      0.35        61\n",
            "           1       0.47      0.88      0.61        48\n",
            "\n",
            "    accuracy                           0.51       109\n",
            "   macro avg       0.59      0.55      0.48       109\n",
            "weighted avg       0.60      0.51      0.46       109\n",
            "\n",
            "Validation AUC: 0.4649931693989071\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:14<00:42,  2.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6880733944954128\n",
            "Validation F1 Score: 0.6802967563837129\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.48      0.63        61\n",
            "           1       0.59      0.96      0.73        48\n",
            "\n",
            "    accuracy                           0.69       109\n",
            "   macro avg       0.76      0.72      0.68       109\n",
            "weighted avg       0.78      0.69      0.67       109\n",
            "\n",
            "Validation AUC: 0.8679986338797814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:17<00:40,  2.88s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7247706422018348\n",
            "Validation F1 Score: 0.7067790530846485\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.87      0.78        61\n",
            "           1       0.76      0.54      0.63        48\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.74      0.71      0.71       109\n",
            "weighted avg       0.73      0.72      0.72       109\n",
            "\n",
            "Validation AUC: 0.8060109289617486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:20<00:36,  2.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7706422018348624\n",
            "Validation F1 Score: 0.7694000169247694\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.75      0.79        61\n",
            "           1       0.72      0.79      0.75        48\n",
            "\n",
            "    accuracy                           0.77       109\n",
            "   macro avg       0.77      0.77      0.77       109\n",
            "weighted avg       0.78      0.77      0.77       109\n",
            "\n",
            "Validation AUC: 0.8329918032786885\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:22<00:33,  2.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6422018348623854\n",
            "Validation F1 Score: 0.5725490196078431\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.93      0.75        61\n",
            "           1       0.76      0.27      0.40        48\n",
            "\n",
            "    accuracy                           0.64       109\n",
            "   macro avg       0.69      0.60      0.57       109\n",
            "weighted avg       0.68      0.64      0.59       109\n",
            "\n",
            "Validation AUC: 0.83025956284153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:25<00:30,  2.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7431192660550459\n",
            "Validation F1 Score: 0.7429245283018868\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.64      0.74        61\n",
            "           1       0.66      0.88      0.75        48\n",
            "\n",
            "    accuracy                           0.74       109\n",
            "   macro avg       0.76      0.76      0.74       109\n",
            "weighted avg       0.77      0.74      0.74       109\n",
            "\n",
            "Validation AUC: 0.8444330601092898\n",
            "Validation Accuracy: 0.8532110091743119\n",
            "Validation F1 Score: 0.8475524475524476\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.93      0.88        61\n",
            "           1       0.90      0.75      0.82        48\n",
            "\n",
            "    accuracy                           0.85       109\n",
            "   macro avg       0.86      0.84      0.85       109\n",
            "weighted avg       0.86      0.85      0.85       109\n",
            "\n",
            "Validation AUC: 0.855191256830601\n",
            "-----------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:31<00:26,  2.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7247706422018348\n",
            "Validation F1 Score: 0.7119450317124736\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.84      0.77        61\n",
            "           1       0.74      0.58      0.65        48\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.73      0.71      0.71       109\n",
            "weighted avg       0.73      0.72      0.72       109\n",
            "\n",
            "Validation AUC: 0.7862021857923498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:34<00:23,  2.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7247706422018348\n",
            "Validation F1 Score: 0.7119450317124736\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.84      0.77        61\n",
            "           1       0.74      0.58      0.65        48\n",
            "\n",
            "    accuracy                           0.72       109\n",
            "   macro avg       0.73      0.71      0.71       109\n",
            "weighted avg       0.73      0.72      0.72       109\n",
            "\n",
            "Validation AUC: 0.8480191256830601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:37<00:20,  2.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.8073394495412844\n",
            "Validation F1 Score: 0.807079646017699\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.75      0.81        61\n",
            "           1       0.74      0.88      0.80        48\n",
            "\n",
            "    accuracy                           0.81       109\n",
            "   macro avg       0.81      0.81      0.81       109\n",
            "weighted avg       0.82      0.81      0.81       109\n",
            "\n",
            "Validation AUC: 0.8859289617486339\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:40<00:17,  2.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7889908256880734\n",
            "Validation F1 Score: 0.7889908256880733\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.70      0.79        61\n",
            "           1       0.70      0.90      0.79        48\n",
            "\n",
            "    accuracy                           0.79       109\n",
            "   macro avg       0.80      0.80      0.79       109\n",
            "weighted avg       0.81      0.79      0.79       109\n",
            "\n",
            "Validation AUC: 0.8931010928961749\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:43<00:14,  2.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7706422018348624\n",
            "Validation F1 Score: 0.7705649574808453\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.67      0.77        61\n",
            "           1       0.68      0.90      0.77        48\n",
            "\n",
            "    accuracy                           0.77       109\n",
            "   macro avg       0.79      0.78      0.77       109\n",
            "weighted avg       0.80      0.77      0.77       109\n",
            "\n",
            "Validation AUC: 0.8828551912568307\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:46<00:11,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7981651376146789\n",
            "Validation F1 Score: 0.798012129380054\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.74      0.80        61\n",
            "           1       0.72      0.88      0.79        48\n",
            "\n",
            "    accuracy                           0.80       109\n",
            "   macro avg       0.80      0.81      0.80       109\n",
            "weighted avg       0.81      0.80      0.80       109\n",
            "\n",
            "Validation AUC: 0.8854166666666666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:48<00:08,  2.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7889908256880734\n",
            "Validation F1 Score: 0.7887062789717658\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.74      0.80        61\n",
            "           1       0.72      0.85      0.78        48\n",
            "\n",
            "    accuracy                           0.79       109\n",
            "   macro avg       0.79      0.80      0.79       109\n",
            "weighted avg       0.80      0.79      0.79       109\n",
            "\n",
            "Validation AUC: 0.8886612021857923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:51<00:05,  2.81s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7889908256880734\n",
            "Validation F1 Score: 0.7887062789717658\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.74      0.80        61\n",
            "           1       0.72      0.85      0.78        48\n",
            "\n",
            "    accuracy                           0.79       109\n",
            "   macro avg       0.79      0.80      0.79       109\n",
            "weighted avg       0.80      0.79      0.79       109\n",
            "\n",
            "Validation AUC: 0.886441256830601\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rEpochs:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:54<00:02,  2.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7798165137614679\n",
            "Validation F1 Score: 0.7796495956873315\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.79        61\n",
            "           1       0.71      0.85      0.77        48\n",
            "\n",
            "    accuracy                           0.78       109\n",
            "   macro avg       0.78      0.79      0.78       109\n",
            "weighted avg       0.79      0.78      0.78       109\n",
            "\n",
            "Validation AUC: 0.8872950819672132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epochs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:57<00:00,  2.86s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7798165137614679\n",
            "Validation F1 Score: 0.7796495956873315\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.72      0.79        61\n",
            "           1       0.71      0.85      0.77        48\n",
            "\n",
            "    accuracy                           0.78       109\n",
            "   macro avg       0.78      0.79      0.78       109\n",
            "weighted avg       0.79      0.78      0.78       109\n",
            "\n",
            "Validation AUC: 0.8852459016393442\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
        "best_accuracy = 0.0\n",
        "lrs = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
        "    resnet.train()  # Set the model to training mode\n",
        "    \n",
        "    epoch_loss = 0.0  # Accumulator for epoch loss\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device, dtype=torch.float)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = resnet(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        \n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Step the learning rate\n",
        "        lrs.append(get_lr(optimizer))\n",
        "        scheduler.step() \n",
        "        \n",
        "        # Accumulate the loss\n",
        "        epoch_loss += loss.item()\n",
        "    \n",
        "    # Compute the average loss for the epoch\n",
        "    epoch_loss /= len(train_loader)\n",
        "\n",
        "    # Validation loop\n",
        "    resnet.eval()  # Set the model to evaluation mode\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "    true_probabilities = []\n",
        "    predicted_probabilities = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device, dtype=torch.float)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = resnet(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "\n",
        "            # Calculate accuracy\n",
        "            total_samples += labels.size(0)\n",
        "            total_correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Collect predicted and true labels for classification report\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            # Collect predicted probabilities and true labels\n",
        "            predicted_probabilities.extend(probabilities[:, 1].cpu().numpy())  # Assuming binary classification\n",
        "            true_probabilities.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = total_correct / total_samples\n",
        "    print(f\"Validation Accuracy: {accuracy}\")\n",
        "\n",
        "    # Compute F1 score and classification report\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "    classification_rep = classification_report(true_labels, predicted_labels)\n",
        "    print(f\"Validation F1 Score: {f1}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_rep)\n",
        "\n",
        "    # Compute the AUC\n",
        "    auc = roc_auc_score(true_probabilities, predicted_probabilities)\n",
        "    print(f\"Validation AUC: {auc}\")\n",
        "    \n",
        "    if accuracy > 0.8 and accuracy > best_accuracy:\n",
        "      print('-----------------------------------------------------------')\n",
        "      model_path = 'ResNet101_Weights'+str(epoch)+'.pth'\n",
        "      best_accuracy = accuracy\n",
        "\n",
        "      # Save the model\n",
        "      torch.save(resnet.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "AwZ79tbO-Bst",
      "metadata": {
        "id": "AwZ79tbO-Bst"
      },
      "outputs": [],
      "source": [
        "resnet.load_state_dict(torch.load('/content/ResNeXt101_Weights11.pth'))\n",
        "\n",
        "resnet = resnet.to(device)\n",
        "\n",
        "torch.save(resnet.state_dict(), '/content/drive/Shareddrives/QB Hacakthon/models path/ResNeXt101_Weights11.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "vxy5xJDTuq74",
        "pa-V67aYumtd",
        "DmAQtWpVuur9",
        "0baf66a2",
        "Lr9dT8gns4mN"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
